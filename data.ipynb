{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import datetime\n",
    "from datetime import date\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_lyrics = pd.read_csv('./lyricspotify.csv')\n",
    "missed = pd.read_csv('./lastfmmissed.csv')\n",
    "lastfm = pd.read_csv('./lastfm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = missed[missed.columns[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastfm = lastfm[lastfm.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_fm_total = pd.concat([lastfm,missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_fm_total = last_fm_total.rename(columns={'track-title':'song'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_fm_total['artist'] = last_fm_total['artist'].apply(lambda x: x.lower())\n",
    "last_fm_total['artist'] = last_fm_total['artist'].apply(lambda x: x.replace(' ', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_lyrics.drop_duplicates(subset=['song'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = spotify_lyrics.merge(last_fm_total, on=['song', 'artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['playcount_percentage'] = final.groupby('album')['playcount'].apply(lambda x: x/(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['is_hit'] = final['playcount_percentage'] >= .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[~final['danceability'].isna()]\n",
    "final = final[~final['lyrics'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_words(lyrics):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(lyrics) \n",
    "    no_stop_words_lyrics = [w for w in word_tokens if not w in stop_words] \n",
    "    unique = set(no_stop_words_lyrics)\n",
    "    return len(unique)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in final.iterrows():\n",
    "  final.loc[idx, 'unique-words'] = count_unique_words(row['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[~final.album.str.contains(\"Hits\")]\n",
    "final = final[~final.artist.str.contains(\"the-beatles\")]\n",
    "final = final[~final.artist.str.contains('michael-jackson')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET RID OF NULL DATES\n",
    "final = final[final.release_date.notnull()]\n",
    "for idx, row in final.iterrows():\n",
    "    final['today']=datetime.datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['age']=np.nan\n",
    "for idx, row in final.iterrows():\n",
    "    date=None\n",
    "    today=None\n",
    "    try:\n",
    "        date = datetime.datetime.strptime(final.loc[idx,'release_date'],\"%Y-%m-%d\")\n",
    "        today = datetime.datetime.strptime(final.loc[idx,'today'],\"%Y-%m-%d\")\n",
    "        final.loc[idx,'age']=abs((today-date).days)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['list_day']=np.nan\n",
    "for idx,row in final.iterrows():\n",
    "    days=None\n",
    "    listnr=None\n",
    "    days=final.loc[idx,'age']\n",
    "    listnr=final.loc[idx, 'listeners']\n",
    "    final.loc[idx,'list_day']=listnr/days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[~final['age'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_nums = final.drop(columns=['Unnamed: 0', 'artist', 'album', 'song','features', \n",
    "                                   'lyrics', 'isrc', 'release_date', 'age',\n",
    "                                   'single_release', 'is_hit', 'today', 'listeners', 'playcount', 'list_day', 'playcount_percentage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = final['is_hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a correlation matrix\n",
    "corr_matrix = feature_nums.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n",
    "\n",
    "#Creating a list of columns to drop\n",
    "to_drop = [column for column in upper.columns if any(upper[column]>0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_nums, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "forest.fit(X_train, y_train)\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626609442060086"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25895269, 0.        , 0.0397694 , 0.05007362, 0.        ,\n",
       "       0.14768945, 0.10083111, 0.14829326, 0.1717046 , 0.08268586])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.estimators_[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('danceability', 0.25895269241316027),\n",
       " ('energy', 0.0),\n",
       " ('loudness', 0.039769404161927785),\n",
       " ('speechiness', 0.050073615313070606),\n",
       " ('liveness', 0.0),\n",
       " ('tempo', 0.14768944767910916),\n",
       " ('valence', 0.10083110914070047),\n",
       " ('duration', 0.1482932643016889),\n",
       " ('track_no', 0.17170460244408353),\n",
       " ('unique-words', 0.08268586454625931)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(names, forest.estimators_[0].feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range (0, n):\n",
    "    forest = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "    forest.fit(X_train, y_train)\n",
    "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "    score = forest.score(X_test, y_test)\n",
    "    importance = forest.estimators_[0].feature_importances_\n",
    "    important_features = list(zip(names, forest.estimators_[0].feature_importances_))\n",
    "    scores.append([score, important_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "danceability = 0\n",
    "loudness = 0 \n",
    "speechiness =0\n",
    "liveness =0\n",
    "tempo =0\n",
    "valence =0\n",
    "duration =0\n",
    "track_no =0\n",
    "unique_words =0\n",
    "    \n",
    "for i in scores: \n",
    "    \n",
    "    score += i[0]\n",
    "    danceability += i[1][0][1]\n",
    "    loudness += i[1][1][1]\n",
    "    speechiness += i[1][2][1]\n",
    "    liveness += i[1][3][1]\n",
    "    tempo += i[1][4][1]\n",
    "    valence += i[1][5][1]\n",
    "    duration += i[1][6][1]\n",
    "    track_no += i[1][7][1]\n",
    "    unique_words += i[1][8][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({'score': score/n, 'danceability': danceability/n, 'speechiness':speechiness/n, 'liveness': liveness/n, 'tempo': tempo/n, 'valence' : valence/n, \n",
    "       'duration': duration/n, 'track': track_no/n, 'unique_words': unique_words/n})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
